{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch einops\n",
    "%pip install numpy==1.24.1\n",
    "%pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\python\\functions-python-pytorch-tutorial\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =[\"\"\"\n",
    "The History and Impact of Artificial Neural Networks\n",
    "\n",
    "Artificial Neural Networks (ANNs) represent a fundamental shift in how we approach computation and artificial intelligence. Inspired by biological neural networks, these systems have evolved from simple perceptrons in the 1950s to today's sophisticated deep learning architectures.\n",
    "\n",
    "Early Development (1940s-1950s):\n",
    "The first artificial neuron was proposed by Warren McCulloch and Walter Pitts in 1943. Their mathematical model showed how neurons might work, demonstrating that simple neural networks could compute basic logical functions. In 1957, Frank Rosenblatt developed the perceptron, the first algorithm that could learn specific patterns through iterative training.\n",
    "\n",
    "The AI Winter (1970s):\n",
    "Despite early promise, neural network research faced significant setbacks in the 1970s. Marvin Minsky and Seymour Papert's 1969 book \"Perceptrons\" highlighted fundamental limitations of single-layer networks, particularly their inability to solve the XOR problem. This led to reduced funding and interest in neural network research, a period known as the \"AI Winter.\"\n",
    "\n",
    "Renaissance (1980s-1990s):\n",
    "The field experienced a revival with several breakthrough developments:\n",
    "1. The backpropagation algorithm became widely recognized as a solution for training multi-layer networks\n",
    "2. Improvements in computer processing power made larger networks feasible\n",
    "3. New architectures like Convolutional Neural Networks (CNNs) emerged\n",
    "4. Successful applications in pattern recognition and speech processing demonstrated practical value\n",
    "\n",
    "Modern Era (2000s-Present):\n",
    "The explosion of big data and computational power has led to remarkable achievements:\n",
    "- Deep learning models have surpassed human performance in various tasks\n",
    "- Applications range from computer vision to natural language processing\n",
    "- Transfer learning has enabled more efficient model training\n",
    "- Architectures like transformers have revolutionized language models\n",
    "\n",
    "Technical Foundations:\n",
    "\n",
    "Neural networks consist of interconnected layers of nodes, each performing weighted calculations:\n",
    "1. Input Layer: Receives raw data\n",
    "2. Hidden Layers: Process information through weighted connections\n",
    "3. Output Layer: Produces final results\n",
    "\n",
    "Key concepts include:\n",
    "- Activation functions (ReLU, sigmoid, tanh)\n",
    "- Weight initialization and adjustment\n",
    "- Loss functions and optimization algorithms\n",
    "- Regularization techniques\n",
    "\n",
    "Practical Applications:\n",
    "\n",
    "Modern neural networks have found applications across numerous fields:\n",
    "* Healthcare: Disease diagnosis, drug discovery, medical image analysis\n",
    "* Finance: Risk assessment, fraud detection, algorithmic trading\n",
    "* Transportation: Autonomous vehicles, traffic prediction, route optimization\n",
    "* Entertainment: Content recommendations, game AI, art generation\n",
    "\n",
    "Challenges and Future Directions:\n",
    "\n",
    "Despite their success, neural networks face several ongoing challenges:\n",
    "1. Interpretability and explainability of decisions\n",
    "2. Energy consumption and computational requirements\n",
    "3. Data privacy and ethical considerations\n",
    "4. Robustness against adversarial attacks\n",
    "\n",
    "Research continues in areas such as:\n",
    "- More efficient architectures\n",
    "- Unsupervised learning approaches\n",
    "- Neuromorphic computing\n",
    "- Integration with symbolic AI systems\n",
    "\n",
    "The field of neural networks continues to evolve rapidly, with new architectures and applications emerging regularly. As our understanding of both biological and artificial neural networks deepens, we can expect further innovations in this transformative technology.  \n",
    "    \"\"\",\n",
    "    \"\"\"The Crystal Songkeeper: A Tale of the Echoing Peaks\n",
    "In the shadow of the Echoing Peaks, where ancient crystals hummed with forgotten melodies, lived a young apprentice named Lyra. Her small cottage, perched precariously on the mountainside, glowed with an ethereal blue light that pulsed in rhythm with the crystals scattered throughout the valley below. Every morning, she would wake to the harmonic resonance of the mountain's song, a symphony that had guided her people for countless generations.\n",
    "\"The crystals are growing restless,\" Lyra whispered to her mentor, Master Theron, one particularly bright morning. The old Songkeeper's eyes, as deep and blue as the crystals themselves, narrowed with concern. \"Yes, young one. The Discord approaches.\" His weathered hands traced the intricate patterns carved into his staff, each line telling the story of songs past.\n",
    "The Discord was no mere legend. Every thousand years, the crystal songs would begin to falter, their harmonies becoming discordant and chaotic. Without intervention, the dissonance would grow until it shattered every crystal in the valley, unleashing catastrophic energy that could reshape the very mountains themselves. According to the ancient texts, only a true Songkeeper could prevent this disaster by performing the Grand Harmony - a complex melody that would restore balance to the crystal network.\n",
    "Lyra spent her days practicing the traditional songs, her voice carrying through the valley as she learned to match the precise frequencies of each crystal type. The basic crystals responded to simple melodies: the blue ones resonated with gentle lullabies, while the green crystals preferred more lively folk tunes. But the rare purple crystals, those were different. They required complex harmonies that few could master.\n",
    "\"Your technique has improved,\" Master Theron observed, watching as Lyra successfully activated a cluster of purple crystals. The crystals pulsed with a deep violet light, their energy synchronizing with her voice. \"But the Grand Harmony requires more than just technical skill. It requires understanding the very essence of the crystal songs.\"\n",
    "One evening, as the setting sun painted the crystals in brilliant hues of orange and pink, Lyra made a discovery. She noticed that when she sang to multiple crystals simultaneously, they didn't just resonate individually - they created entirely new harmonies between themselves. \"Master Theron!\" she called excitedly. \"Listen to this!\" She demonstrated her finding, causing three different crystal types to create an intricate counterpoint that none of them could produce alone.\n",
    "The old Songkeeper's eyes widened in amazement. \"In all my years...\" he muttered, stroking his silver beard. \"Child, you may have uncovered something that was lost to time. The ancient texts speak of the Crystal Chorus - the ability to weave multiple crystal songs into a single, greater harmony.\"\n",
    "Over the next few weeks, Lyra devoted herself to exploring this new technique. She mapped the relationships between different crystal types, creating complex musical patterns that hadn't been heard in centuries. The valley seemed to come alive with her experiments, the crystals glowing brighter and more vibrantly than anyone could remember.\n",
    "But time was running short. The signs of the approaching Discord grew more obvious each day. Crystal formations that had sung the same melodies for generations began to waver, their songs becoming erratic and unpredictable. Small fissures appeared in some of the larger crystals, sending discordant notes echoing through the valley.\n",
    "When the day of the Discord finally arrived, the sky darkened with ominous clouds that swirled above the highest peaks. The crystals throughout the valley pulsed with irregular rhythms, their usual harmonious songs degrading into chaos. Master Theron looked at Lyra with a mix of pride and concern. \"It's time,\" he said simply.\n",
    "Lyra took her position in the Crystal Amphitheater, an ancient structure formed from crystalline formations that spiraled up the mountainside. As she began to sing, she didn't follow the traditional Grand Harmony that had been passed down through generations. Instead, she used her understanding of the Crystal Chorus to weave together the songs of every crystal type in the valley.\n",
    "The effect was immediate and extraordinary. Waves of colored light rippled through the crystal networks, each formation adding its voice to her song. The discordant energies that had been building for months began to shift and change, finding new patterns within her complex harmony. Even the oldest and largest crystals, which had remained dormant for centuries, awakened to join her symphony.\n",
    "Master Theron watched in awe as his apprentice conducted the largest Crystal Chorus ever attempted. \"She's not just preventing the Discord,\" he realized. \"She's transforming it into something new.\" The chaotic energies that threatened to shatter the crystals were being reformed into stable, beautiful harmonies that strengthened the very formations they had meant to destroy.\n",
    "Hours passed as Lyra maintained the incredible performance, her voice never wavering as she guided the crystal energies into their new configuration. When the last notes finally faded away, the valley had been transformed. The crystals glowed with a steady, brilliant light, their songs clearer and stronger than ever before.\n",
    "\"You've done more than save the valley,\" Master Theron said, tears in his eyes. \"You've elevated our art to heights we never imagined possible.\" Lyra smiled, exhausted but proud. She could feel the crystals humming contentedly, their songs now interwoven in ways that would prevent the Discord from ever threatening the valley again.\n",
    "In the years that followed, Lyra's discovery of the Crystal Chorus revolutionized the art of crystal singing. She established a new school of Songkeeping that taught not just the individual songs of each crystal type, but the complex harmonies that could be created between them. The Echoing Peaks became known not just as a place of power, but as the birthplace of a new age of crystal harmony.\n",
    "And on quiet evenings, when the sun's last rays caught the crystal formations just right, visitors to the valley would sometimes see a figure standing in the Crystal Amphitheater, her voice rising and falling with the eternal songs of the mountains. For Lyra had become more than just a Songkeeper - she had become part of the very melody of the peaks themselves, her legacy resonating through the crystals for generations to come.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute mean pooling for segment-level token embeddings.\n",
    "    \n",
    "    Args:\n",
    "        token_embeddings: Token embeddings of shape [num_tokens, hidden_dim]\n",
    "        attention_mask: Attention mask of shape [num_tokens]\n",
    "    \n",
    "    Returns:\n",
    "        Pooled embedding of shape [hidden_dim]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add batch dimension if not present\n",
    "    if token_embeddings.dim() == 2:\n",
    "        token_embeddings = token_embeddings.unsqueeze(0)  # [1, num_tokens, hidden_dim]\n",
    "    if attention_mask.dim() == 1:\n",
    "        attention_mask = attention_mask.unsqueeze(0)      # [1, num_tokens]\n",
    "        \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    return (sum_embeddings / sum_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_with_delimiter(text: str, delimiters: List[str]) -> Tuple[List[str], List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Split text on multiple delimiters and return segments with their offsets.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to split\n",
    "        delimiters: List of delimiter strings\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - List of segments\n",
    "        - List of (start, end) offsets for each segment\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    escaped_delimiters = [re.escape(d) for d in delimiters]\n",
    "    pattern = f\"[^{''.join(escaped_delimiters)}]*[{''.join(escaped_delimiters)}]|[^{''.join(escaped_delimiters)}]+$\"\n",
    "    \n",
    "\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    segments, offsets = [], []\n",
    "    for match in matches:\n",
    "        segment = match.group().strip()\n",
    "        if segment: \n",
    "            segments.append(segment)\n",
    "            offsets.append((match.start(), match.end()))\n",
    "    \n",
    "    return segments, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_tuples(\n",
    "    list1: List[Tuple[int, int]], \n",
    "    list2: List[Tuple[int, int]]\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Find indices in list2 where tuples overlap with any tuple in list1.\n",
    "    A tuple overlaps if its range intersects with another tuple's range.\n",
    "    \n",
    "    Args:\n",
    "        list1: First list of (start, end) tuples\n",
    "        list2: Second list of (start, end) tuples\n",
    "    \n",
    "    Returns:\n",
    "        List of indices from list1 where tuples overlap with list2\n",
    "    \"\"\"\n",
    "    overlapping_indices_list = []\n",
    "    \n",
    "    for (start1, end1) in list1:\n",
    "        overlapping_indices = []\n",
    "        for idx, (start2, end2) in enumerate(list2):\n",
    "            if (start2 <= end1 and end2 >= start1):\n",
    "                overlapping_indices.append(idx)\n",
    "            if start2 > end1:\n",
    "                break\n",
    "        overlapping_indices_list.append(overlapping_indices)\n",
    "    \n",
    "    return overlapping_indices_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_segmentation(\n",
    "    values, \n",
    "    min_chunk_size, \n",
    "    max_chunk_size\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Segments the input values into chunks that maximize the similarity within each chunk.\n",
    "    \n",
    "    Args:\n",
    "        values (numpy.ndarray): A 2D array where each row represents a data point.\n",
    "        min_chunk_size (int): The minimum size of each chunk.\n",
    "        max_chunk_size (int): The maximum size of each chunk.\n",
    "        \n",
    "    Returns:\n",
    "        list of tuples: A list of tuples where each tuple represents the start and end indices of a chunk.\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    similarity_matrix = np.dot(values, values.T)\n",
    "    mean_similarity = np.mean(similarity_matrix[np.triu_indices(similarity_matrix.shape[0], k=1)])\n",
    "    similarity_matrix = similarity_matrix - mean_similarity\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "\n",
    "    dp = np.zeros(n)\n",
    "    segmentation = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        max_reward = float('-inf')\n",
    "        best_start = i\n",
    "\n",
    "        for size in range(min_chunk_size, min(max_chunk_size + 1, i + 2)):\n",
    "            if i - size + 1 >= 0:\n",
    "                reward = np.sum(similarity_matrix[i - size + 1:i + 1, i - size + 1:i + 1])\n",
    "                if i - size >= 0:\n",
    "                    reward += dp[i - size]\n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    best_start = i - size + 1\n",
    "\n",
    "        dp[i] = max_reward\n",
    "        segmentation[i] = best_start\n",
    "\n",
    "    boundaries = []\n",
    "    i = n - 1\n",
    "    while i >= 0:\n",
    "        boundaries.append((segmentation[i], i))\n",
    "        i = segmentation[i] - 1\n",
    "\n",
    "    boundaries.reverse()\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\python\\functions-python-pytorch-tutorial\\.venv\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Embedding model\n",
    "\n",
    "task: str = 'retrieval.passage'\n",
    "max_tokens: int = 8192\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v3\", use_fast=True)\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# multilingual NER model\n",
    "\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model.eval()\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, grouped_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get all tokens, offsets, and attention masks for the documents\n",
    "\n",
    "documents = []\n",
    "for doc in docs:\n",
    "    doc_tokens = tokenizer(\n",
    "        doc,\n",
    "        return_offsets_mapping=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=False,\n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    doc_tokens['text'] = doc\n",
    "    documents.append(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 740, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: get embedding at the token level for all documents\n",
    "\n",
    "max_tokens = 8192\n",
    "\n",
    "for document in documents:\n",
    "    doc_input_ids = torch.split(document['input_ids'], max_tokens, dim=1)\n",
    "    doc_attention_mask = torch.split(document['attention_mask'], max_tokens, dim=1)\n",
    "    doc_offsets = torch.split(document['offset_mapping'], max_tokens, dim=1)\n",
    "    \n",
    "    doc_embeddings = []\n",
    "    for input_ids, attention_mask, offsets in zip(doc_input_ids, doc_attention_mask, doc_offsets):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            tokens_embeddings = outputs.last_hidden_state\n",
    "            doc_embeddings.append(tokens_embeddings)   \n",
    "    \n",
    "    document['tokens_embeddings'] = torch.concat(doc_embeddings, dim=1)\n",
    "documents[0]['tokens_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute mean-pooled embeddings for each document at the low level structure level\n",
    "\n",
    "split_delimiters: List[str] = [\".\", \"!\", \"?\", \":\", \"\\n\"]\n",
    "\n",
    "for document in documents:\n",
    "    segments_text, segment_offset= split_with_delimiter(document['text'], split_delimiters)\n",
    "    segments_tokens_idx = find_overlapping_tuples(segment_offset, document['offset_mapping'][0])\n",
    "    segments = []\n",
    "    for segment_token_idx in segments_tokens_idx:\n",
    "        segment_tokens_embeddings = document['tokens_embeddings'][0][segment_token_idx]\n",
    "        segment_attention_mask = document['attention_mask'][0][segment_token_idx]\n",
    "        segment_embeddings = mean_pooling(segment_tokens_embeddings, segment_attention_mask)\n",
    "        segments.append(segment_embeddings)\n",
    "    document['segments_embeddings'] = torch.stack(segments)\n",
    "    document['segments_text'] = segments_text\n",
    "    document['segments_offset'] = segment_offset  \n",
    "    document['segments_tokens_offset'] = [(min(seg), max(seg)) for seg in segments_tokens_idx]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fleut\\AppData\\Local\\Temp\\ipykernel_27000\\3697090508.py:18: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  similarity_matrix = np.dot(values, values.T)\n"
     ]
    }
   ],
   "source": [
    "# Step 4 : build optimal chunks for each document\n",
    "\n",
    "min_chunk_size = 5\n",
    "max_chunk_size = 20\n",
    "for document in documents:\n",
    "    boundaries = optimal_segmentation(document['segments_embeddings'], min_chunk_size, max_chunk_size)\n",
    "    chunk_text, chunk_embedding = [],[]\n",
    "    for (first_segment, last_segment) in boundaries:\n",
    "        start_token = document['segments_tokens_offset'][first_segment][0]\n",
    "        end_token = document['segments_tokens_offset'][last_segment][1]+1\n",
    "        chunk_tokens_embeddings = document['tokens_embeddings'][0, start_token:end_token]\n",
    "        chunk_attention_mask = document['attention_mask'][0, start_token:end_token]\n",
    "        chunk_text.append(\" \".join(document['segments_text'][first_segment:last_segment+1]))\n",
    "        chunk_embedding.append(mean_pooling(chunk_tokens_embeddings, chunk_attention_mask))   \n",
    "    document['chunks_text'] = chunk_text\n",
    "    document['chunks_embedding'] = torch.stack(chunk_embedding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Extracting keywords\n",
    "\n",
    "for document in documents:\n",
    "    chunks_keywords = []\n",
    "    for chunk in document['chunks_text']:\n",
    "        entities = ner_pipeline(chunk)\n",
    "        # TODO: filter entities based on confidence score and type (entity['entity_group'], entity['score'])\n",
    "        chunks_keywords.append([entity['word'] for entity in entities])\n",
    "    document['chunks_keywords'] = chunks_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Extracting keyphrases with bm25\n",
    "# TODO: one separate BM25 per chunk\n",
    "\n",
    "chunks_text = [doc['chunks_text'] for doc in documents]\n",
    "flattened_chunks_text = [chunk for sublist in chunks_text for chunk in sublist]\n",
    "tokenized_chunks = [chunk.split() for chunk in flattened_chunks_text]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "for document in documents:\n",
    "    bm25_embeddings = []    \n",
    "    for chunk in document['chunks_text']:\n",
    "        bm25_embedding = bm25.get_scores(chunk)\n",
    "        bm25_embeddings.append(bm25_embedding)\n",
    "    document['chunks_bm25'] = bm25_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'chunks_text', 'chunks_embedding', 'chunks_keywords', 'chunks_bm25'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning step\n",
    "for doc in documents:\n",
    "    for k in ['input_ids', 'attention_mask', 'offset_mapping', 'tokens_embeddings', 'segments_embeddings', 'segments_text', 'segments_offset', 'segments_tokens_offset']:\n",
    "        doc.pop(k)\n",
    "documents[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the practical applications of neural networks?\"\n",
    "query_tokens = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "query_tokens_embeddings = model(**query_tokens.to(device))\n",
    "query_embeddings = mean_pooling(query_tokens_embeddings.last_hidden_state, query_tokens['attention_mask'])\n",
    "query_bm25 = bm25.get_scores(query.split())\n",
    "query_keywords = [entity['word'] for entity in ner_pipeline(query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords: ['neu']\n",
      "bm25: [3.46378043 4.85887784 1.01981112 0.         3.42006948 0.87089473\n",
      " 0.         4.89224418 3.14475968 1.82215622 1.89617406 1.9507797\n",
      " 1.92552558 1.0941129  0.98224641 2.25799814]\n",
      "query embedding: tensor([ 1.0069, -2.5083, -0.2263,  ..., -0.6470,  0.8299,  0.3015])\n"
     ]
    }
   ],
   "source": [
    "print(f\"keywords: {query_keywords}\")\n",
    "print(f\"bm25: {query_bm25}\")\n",
    "print(f\"query embedding: {query_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk: The History and Impact of Artificial Neural Networks Artificial Neural Networks (ANNs) represent a fundamental shift in how we approach computation and artificial intelligence. Inspired by biological neural networks, these systems have evolved from simple perceptrons in the 1950s to today's sophisticated deep learning architectures. Early Development (1940s-1950s): The first artificial neuron was proposed by Warren McCulloch and Walter Pitts in 1943. Their mathematical model showed how neurons might work, demonstrating that simple neural networks could compute basic logical functions. In 1957, Frank Rosenblatt developed the perceptron, the first algorithm that could learn specific patterns through iterative training. The AI Winter (1970s): Despite early promise, neural network research faced significant setbacks in the 1970s. Marvin Minsky and Seymour Papert's 1969 book \"Perceptrons\" highlighted fundamental limitations of single-layer networks, particularly their inability to solve the XOR problem. This led to reduced funding and interest in neural network research, a period known as the \"AI Winter. \" Renaissance (1980s-1990s): The field experienced a revival with several breakthrough developments: 1. The backpropagation algorithm became widely recognized as a solution for training multi-layer networks 2. Improvements in computer processing power made larger networks feasible 3. New architectures like Convolutional Neural Networks (CNNs) emerged\n",
      "keywords: ['History and Impact of Artificial Neural Networks Artificial Neural Networks', 'Early Development', 'Warren McCulloch', 'Walter Pitts', 'Frank Rosenblatt', 'AI Winter', 'Marvin Minsky', 'Seymour Papert', 'Perceptrons', 'AI Winter', 'Renaissance', 'Convolutional Neural Networks']\n",
      "bm25: [63.54518163  1.82867441  0.          0.          1.75895311  0.\n",
      "  1.46268848  1.78822444 66.48347952 87.99261355  0.         46.25374195\n",
      "  0.          3.18563796 53.84231512 71.52225936]\n",
      "embedding: tensor([ 1.7566, -2.5426, -0.3610,  ..., -0.1441,  0.0539,  0.3726])\n",
      "\n",
      "chunk: 4. Successful applications in pattern recognition and speech processing demonstrated practical value Modern Era (2000s-Present): The explosion of big data and computational power has led to remarkable achievements: - Deep learning models have surpassed human performance in various tasks - Applications range from computer vision to natural language processing - Transfer learning has enabled more efficient model training - Architectures like transformers have revolutionized language models\n",
      "keywords: ['Modern Era']\n",
      "bm25: [28.31763726  2.28584301  0.          0.          2.19869139  0.\n",
      "  1.82836059  2.23528055 29.9011822  28.9728099   0.         21.26608825\n",
      "  0.          0.         23.12016497 33.43904635]\n",
      "embedding: tensor([ 1.8006, -2.4554, -0.2709,  ..., -0.1973, -0.1236,  0.4348])\n",
      "\n",
      "chunk: Technical Foundations: Neural networks consist of interconnected layers of nodes, each performing weighted calculations: 1. Input Layer: Receives raw data\n",
      "keywords: ['Input Layer']\n",
      "bm25: [7.78735025 0.         0.         0.         0.         0.\n",
      " 0.         0.         7.4029088  9.42238594 0.         5.84817427\n",
      " 0.         0.         6.35804537 8.95420446]\n",
      "embedding: tensor([ 1.4541, -2.0916, -0.2513,  ..., -0.1666,  0.0774,  0.3747])\n",
      "\n",
      "chunk: 2. Hidden Layers: Process information through weighted connections 3. Output Layer:\n",
      "keywords: ['Hidden Layers', 'Output Layer']\n",
      "bm25: [2.12382279 0.         0.         0.         0.         0.\n",
      " 0.         0.         2.01897513 6.85935311 0.         1.59495662\n",
      " 0.         0.         1.73401237 2.44205576]\n",
      "embedding: tensor([ 1.3751, -1.9157, -0.3149,  ..., -0.1485,  0.0408,  0.1458])\n",
      "\n",
      "chunk: Produces final results Key concepts include: - Activation functions (ReLU, sigmoid, tanh) - Weight initialization and adjustment - Loss functions and optimization algorithms - Regularization techniques Practical Applications: Modern neural networks have found applications across numerous fields: * Healthcare: Disease diagnosis, drug discovery, medical image analysis * Finance: Risk assessment, fraud detection, algorithmic trading * Transportation: Autonomous vehicles, traffic prediction, route optimization * Entertainment: Content recommendations, game AI, art generation Challenges and Future Directions: Despite their success, neural networks face several ongoing challenges:\n",
      "keywords: ['Future Directions']\n",
      "bm25: [33.98116471  1.82867441  0.          0.         19.13632193  0.\n",
      "  1.46268848  1.78822444 37.54409431 31.28446472  0.         25.5193059\n",
      "  0.          0.         27.74419796 39.77553447]\n",
      "embedding: tensor([ 1.6796, -2.3704, -0.2628,  ..., -0.2635, -0.1263,  0.2428])\n",
      "\n",
      "chunk: 1. Interpretability and explainability of decisions 2. Energy consumption and computational requirements 3.\n",
      "keywords: ['Energy']\n",
      "bm25: [ 4.95558652  0.          0.          0.          0.          0.\n",
      "  0.          0.          4.71094196 11.86605845  0.          3.72156544\n",
      "  0.          0.          4.04602887  5.69813011]\n",
      "embedding: tensor([ 1.5765, -2.0919, -0.1586,  ..., -0.2910, -0.1867,  0.2397])\n",
      "\n",
      "chunk: Data privacy and ethical considerations 4. Robustness against adversarial attacks Research continues in areas such as: - More efficient architectures\n",
      "keywords: []\n",
      "bm25: [12.74293677  0.4571686   0.          0.          0.43973828  0.\n",
      "  0.36567212  0.44705611 12.23427333 14.08944455  0.          9.56973971\n",
      "  0.          0.         10.40407424 14.82799514]\n",
      "embedding: tensor([ 1.6473, -2.3098, -0.1486,  ..., -0.1741, -0.2637,  0.2591])\n",
      "\n",
      "chunk: - Unsupervised learning approaches - Neuromorphic computing - Integration with symbolic AI systems The field of neural networks continues to evolve rapidly, with new architectures and applications emerging regularly. As our understanding of both biological and artificial neural networks deepens, we can expect further innovations in this transformative technology.\n",
      "keywords: ['Neu']\n",
      "bm25: [14.86675956  1.3715058   0.          0.          1.31921484  0.\n",
      "  1.09701636  1.34116833 16.8734946  18.9680944   0.         11.16469633\n",
      "  0.          0.         12.13808661 17.62137205]\n",
      "embedding: tensor([ 1.8881, -2.4364, -0.2753,  ..., -0.2366, -0.0677,  0.5124])\n",
      "\n",
      "chunk: The Crystal Songkeeper: A Tale of the Echoing Peaks In the shadow of the Echoing Peaks, where ancient crystals hummed with forgotten melodies, lived a young apprentice named Lyra. Her small cottage, perched precariously on the mountainside, glowed with an ethereal blue light that pulsed in rhythm with the crystals scattered throughout the valley below. Every morning, she would wake to the harmonic resonance of the mountain's song, a symphony that had guided her people for countless generations. \"The crystals are growing restless,\" Lyra whispered to her mentor, Master Theron, one particularly bright morning. The old Songkeeper's eyes, as deep and blue as the crystals themselves, narrowed with concern. \"Yes, young one. The Discord approaches. \" His weathered hands traced the intricate patterns carved into his staff, each line telling the story of songs past. The Discord was no mere legend. Every thousand years, the crystal songs would begin to falter, their harmonies becoming discordant and chaotic. Without intervention, the dissonance would grow until it shattered every crystal in the valley, unleashing catastrophic energy that could reshape the very mountains themselves. According to the ancient texts, only a true Songkeeper could prevent this disaster by performing the Grand Harmony - a complex melody that would restore balance to the crystal network. Lyra spent her days practicing the traditional songs, her voice carrying through the valley as she learned to match the precise frequencies of each crystal type. The basic crystals responded to simple melodies: the blue ones resonated with gentle lullabies, while the green crystals preferred more lively folk tunes. But the rare purple crystals, those were different. They required complex harmonies that few could master. \"Your technique has improved,\" Master Theron observed, watching as Lyra successfully activated a cluster of purple crystals.\n",
      "keywords: ['Crystal Songkeeper : A Tale of the Echoing Peaks', 'Echo', '##ing Peaks', 'Lyra', 'Lyra', 'Theron', 'Songkeeper', 'Discord', 'Discord', 'Songkeeper', 'Grand Harmony', 'Lyra', 'Theron', 'Lyra']\n",
      "bm25: [ 81.51292427   0.4571686    0.           0.           0.43973828\n",
      "   0.           0.36567212   0.44705611  79.45641534 119.67293539\n",
      "   0.          59.0133949    0.           4.77845694  69.49239226\n",
      "  90.53172372]\n",
      "embedding: tensor([ 3.0125, -0.9692,  1.2658,  ...,  0.0516,  0.2729,  0.5320])\n",
      "\n",
      "chunk: The crystals pulsed with a deep violet light, their energy synchronizing with her voice. \"But the Grand Harmony requires more than just technical skill. It requires understanding the very essence of the crystal songs. \" One evening, as the setting sun painted the crystals in brilliant hues of orange and pink, Lyra made a discovery. She noticed that when she sang to multiple crystals simultaneously, they didn't just resonate individually - they created entirely new harmonies between themselves. \"Master Theron! \" she called excitedly. \"Listen to this! \" She demonstrated her finding, causing three different crystal types to create an intricate counterpoint that none of them could produce alone. The old Songkeeper's eyes widened in amazement. \"In all my years. . . \" he muttered, stroking his silver beard. \"Child, you may have uncovered something that was lost to time. The ancient texts speak of the Crystal Chorus - the ability to weave multiple crystal songs into a single, greater harmony. \" Over the next few weeks, Lyra devoted herself to exploring this new technique. She mapped the relationships between different crystal types, creating complex musical patterns that hadn't been heard in centuries.\n",
      "keywords: ['Grand Harmony', 'Lyra', 'Theron', 'Songkeeper', 'Crystal Chorus', 'Lyra']\n",
      "bm25: [49.48608015  0.9143372   0.          0.          0.87947656  0.\n",
      "  0.73134424  0.89411222 46.39684295 91.95034911  0.         33.494089\n",
      "  0.          7.9640949  45.30415062 51.63449212]\n",
      "embedding: tensor([ 2.9897, -0.7916,  1.3429,  ...,  0.0587,  0.1851,  0.5468])\n",
      "\n",
      "chunk: The valley seemed to come alive with her experiments, the crystals glowing brighter and more vibrantly than anyone could remember. But time was running short. The signs of the approaching Discord grew more obvious each day. Crystal formations that had sung the same melodies for generations began to waver, their songs becoming erratic and unpredictable. Small fissures appeared in some of the larger crystals, sending discordant notes echoing through the valley.\n",
      "keywords: ['Discord']\n",
      "bm25: [21.23822794  0.          0.          0.          0.          0.\n",
      "  0.          0.         20.18975126 31.34164184  0.         15.94956619\n",
      "  0.          0.         17.34012373 24.42055761]\n",
      "embedding: tensor([ 2.9963, -0.8670,  1.2100,  ...,  0.1391,  0.3032,  0.5227])\n",
      "\n",
      "chunk: When the day of the Discord finally arrived, the sky darkened with ominous clouds that swirled above the highest peaks. The crystals throughout the valley pulsed with irregular rhythms, their usual harmonious songs degrading into chaos. Master Theron looked at Lyra with a mix of pride and concern. \"It's time,\" he said simply. Lyra took her position in the Crystal Amphitheater, an ancient structure formed from crystalline formations that spiraled up the mountainside.\n",
      "keywords: ['Discord', 'Theron', 'Lyra', 'Lyra', 'Crystal Amphitheater']\n",
      "bm25: [22.21538824  0.          0.          0.          0.          0.\n",
      "  0.          0.         22.1309558  33.73586567  0.         15.94956619\n",
      "  0.          1.59281898 19.11810188 24.42055761]\n",
      "embedding: tensor([ 2.9582, -0.9501,  1.2944,  ...,  0.1134,  0.2303,  0.4768])\n",
      "\n",
      "chunk: As she began to sing, she didn't follow the traditional Grand Harmony that had been passed down through generations. Instead, she used her understanding of the Crystal Chorus to weave together the songs of every crystal type in the valley. The effect was immediate and extraordinary. Waves of colored light rippled through the crystal networks, each formation adding its voice to her song. The discordant energies that had been building for months began to shift and change, finding new patterns within her complex harmony. Even the oldest and largest crystals, which had remained dormant for centuries, awakened to join her symphony.\n",
      "keywords: ['Grand Harmony', 'Crystal Chorus']\n",
      "bm25: [29.02557819  0.          0.          0.          0.          0.\n",
      "  0.          0.         28.78236056 40.76402778  0.         21.79774046\n",
      "  0.          0.         23.69816909 33.37476206]\n",
      "embedding: tensor([ 3.0505, -0.7292,  1.2279,  ...,  0.1493,  0.2423,  0.5566])\n",
      "\n",
      "chunk: Master Theron watched in awe as his apprentice conducted the largest Crystal Chorus ever attempted. \"She's not just preventing the Discord,\" he realized. \"She's transforming it into something new. \" The chaotic energies that threatened to shatter the crystals were being reformed into stable, beautiful harmonies that strengthened the very formations they had meant to destroy. Hours passed as Lyra maintained the incredible performance, her voice never wavering as she guided the crystal energies into their new configuration.\n",
      "keywords: ['Theron', 'Crystal Chorus', 'Discord', 'Lyra']\n",
      "bm25: [24.60843039  0.          0.          0.          0.          0.\n",
      "  0.          0.         23.03874274 37.39171253  0.         17.0128706\n",
      "  0.          3.18563796 22.05208829 26.04859478]\n",
      "embedding: tensor([ 3.0122, -0.7165,  1.2346,  ...,  0.0914,  0.1035,  0.5209])\n",
      "\n",
      "chunk: When the last notes finally faded away, the valley had been transformed. The crystals glowed with a steady, brilliant light, their songs clearer and stronger than ever before. \"You've done more than save the valley,\" Master Theron said, tears in his eyes. \"You've elevated our art to heights we never imagined possible. \" Lyra smiled, exhausted but proud.\n",
      "keywords: ['Theron', 'Lyra']\n",
      "bm25: [20.36078481  0.          0.          0.          0.          0.\n",
      "  0.          0.         19.00079249 33.60684345  0.         13.82295736\n",
      "  0.          3.18563796 18.58406355 21.16448326]\n",
      "embedding: tensor([ 2.7586, -0.9223,  1.2515,  ...,  0.0506,  0.1529,  0.5423])\n",
      "\n",
      "chunk: She could feel the crystals humming contentedly, their songs now interwoven in ways that would prevent the Discord from ever threatening the valley again. In the years that followed, Lyra's discovery of the Crystal Chorus revolutionized the art of crystal singing. She established a new school of Songkeeping that taught not just the individual songs of each crystal type, but the complex harmonies that could be created between them. The Echoing Peaks became known not just as a place of power, but as the birthplace of a new age of crystal harmony. And on quiet evenings, when the sun's last rays caught the crystal formations just right, visitors to the valley would sometimes see a figure standing in the Crystal Amphitheater, her voice rising and falling with the eternal songs of the mountains. For Lyra had become more than just a Songkeeper - she had become part of the very melody of the peaks themselves, her legacy resonating through the crystals for generations to come.\n",
      "keywords: ['Discord', 'Lyra', 'Crystal Chorus', 'Songkeeping', 'Echoing Peaks', 'Crystal Amphitheater', 'Lyra', 'Songkeeper']\n",
      "bm25: [41.76851496  0.4571686   0.          0.          0.43973828  0.\n",
      "  0.36567212  0.44705611 42.20633439 52.37001304  0.         31.36748017\n",
      "  0.          0.         34.10224333 48.2027572 ]\n",
      "embedding: tensor([ 3.0102, -0.7792,  1.1372,  ...,  0.1035,  0.2298,  0.5763])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "    for chunk_text, chunk_bm25, chunk_embedding, chunk_keywords in zip(document['chunks_text'], document['chunks_bm25'], document['chunks_embedding'], document['chunks_keywords']):\n",
    "        print(f\"chunk: {chunk_text}\")\n",
    "        print(f\"keywords: {chunk_keywords}\")\n",
    "        print(f\"bm25: {chunk_bm25}\")\n",
    "        print(f\"embedding: {chunk_embedding}\")\n",
    "        bm25_score = bm25.get\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      3\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m411\u001b[39m)\n\u001b[0;32m      4\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(token_embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=64, random_state=411)\n",
    "kmeans.fit(token_embeddings.cpu().numpy())\n",
    "\n",
    "# Normalize the token embeddings and cluster centers\n",
    "normalized_token_embeddings = F.normalize(token_embeddings, p=2, dim=1)\n",
    "concepts = F.normalize(torch.tensor(kmeans.cluster_centers_), p=2, dim=1)\n",
    "\n",
    "# Compute the cosine similarity\n",
    "concepts_target = torch.mm(normalized_token_embeddings, concepts.T)\n",
    "\n",
    "concepts.shape, concepts_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries  = [\n",
    "    \"What were the major developments in neural networks during the 1980s and 1990s?\",\n",
    "    \"Explain the basic components of a neural network's architecture.\",\n",
    "    \"What are the current applications of neural networks in healthcare?\",\n",
    "    \"What caused the AI Winter in the 1970s?\",\n",
    "    \"What are the main challenges facing neural networks today?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_token_embeddings, _, query_attention_mask = get_embedding(queries[1:2])\n",
    "query_embedding = mean_pooling(query_token_embeddings.unsqueeze(0), query_attention_mask.unsqueeze(0))\n",
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between query embedding and chunk embeddings\n",
    "similarities = cosine_similarity(query_embedding.cpu().numpy(), np.stack([chunk['embedding'].cpu().numpy() for chunk in chunks]))\n",
    "\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"chunk: {i}\")\n",
    "    print(f\"Similarity: {np.max(similarity)}\")\n",
    "    print()\n",
    "    \n",
    "# Get the most similar chunks\n",
    "print(\"most similar chunk:\")\n",
    "most_similar_idx = np.argmax(similarities)\n",
    "most_similar_chunk = chunks[most_similar_idx]\n",
    "\n",
    "most_similar_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "concept_similarities = cosine_similarity(query_embedding.cpu().numpy(), concepts.cpu().numpy())\n",
    "\n",
    "concepts_target_np = np.array(concepts_target)\n",
    "concept_similarities_np = np.array(concept_similarities.T)\n",
    "token_importances = np.dot(concepts_target_np, concept_similarities_np)[:,0]\n",
    "token_importances = (token_importances - np.min(token_importances)) / (np.max(token_importances) - np.min(token_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dense_subsequences(\n",
    "    values: np.ndarray,\n",
    "    min_size: int = 1,\n",
    "    max_size: int = None,\n",
    "    num_sequences: int = 3,\n",
    "    min_density: float = None,\n",
    "    min_gap: int = 0\n",
    ") -> list[tuple[int, int, float]]:\n",
    "\n",
    "    if max_size is None:\n",
    "        max_size = len(values)\n",
    "        \n",
    "    n = len(values)\n",
    "    results = []\n",
    "    used_positions = np.zeros(n, dtype=bool)\n",
    "\n",
    "    def is_valid_region(start: int, end: int) -> bool:\n",
    "        for s in range(max(0, start - min_gap), min(n, end + min_gap)):\n",
    "            if used_positions[s]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    cumsum = np.concatenate(([0], np.cumsum(values)))\n",
    "    \n",
    "    while len(results) < num_sequences:\n",
    "        max_density = float('-inf')\n",
    "        best_start = None\n",
    "        best_end = None\n",
    "        \n",
    "\n",
    "        for length in range(min_size, min(n + 1, max_size + 1)):\n",
    "            for start in range(n - length + 1):\n",
    "                end = start + length\n",
    "\n",
    "                if not is_valid_region(start, end):\n",
    "                    continue\n",
    "\n",
    "                curr_sum = cumsum[end] - cumsum[start]\n",
    "                density = curr_sum / length\n",
    "                \n",
    "                if density > max_density:\n",
    "                    max_density = density\n",
    "                    best_start = start\n",
    "                    best_end = end\n",
    "\n",
    "        if best_start is None or (min_density is not None and max_density < min_density):\n",
    "            break\n",
    "\n",
    "        used_positions[best_start:best_end] = True\n",
    "        results.append((best_start, best_end, max_density))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_results = find_dense_subsequences(token_importances, min_size=20, max_size=100, num_sequences=3, min_density=0.2, min_gap=10)\n",
    "print(f\"Found {len(concepts_results)} dense passages:\")\n",
    "for start, end, density in concepts_results:\n",
    "    text_start = offsets_mapping[start][0].item()\n",
    "    text_end = offsets_mapping[end][1].item()\n",
    "    dense_passage = docs[0][text_start:text_end]\n",
    "    print(f\"Dense Passage: {dense_passage}\")\n",
    "    print(f\"Density: {density}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
